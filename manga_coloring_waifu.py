#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šç”¨æ¼«ç•«è‡ªå‹•ä¸Šè‰²ç³»çµ± - Waifu Diffusion ç‰ˆæœ¬ï¼ˆç„¡é‚Šç·£æª¢æ¸¬ï¼‰
"""

import torch
import gradio as gr
import numpy as np
import cv2
from PIL import Image, ImageFilter, ImageOps, ImageEnhance
from diffusers import StableDiffusionImg2ImgPipeline

class UniversalMangaColoringSystem:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # è¼‰å…¥ Waifu Diffusion æ¨¡å‹
        self._load_model()
    
    def _load_model(self):
        """è¼‰å…¥ Waifu Diffusion æ¨¡å‹ - å°ˆé–€é‡å°å‹•æ¼«é¢¨æ ¼"""
        print("ğŸš€ è¼‰å…¥ Waifu Diffusion æ¨¡å‹...")
        
        try:
            # ä½¿ç”¨ Waifu Diffusionï¼Œæ›´é©åˆå‹•æ¼«é¢¨æ ¼
            self.pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
                "hakurei/waifu-diffusion",
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                safety_checker=None,
                requires_safety_checker=False
            ).to(self.device)
            
            # å•Ÿç”¨è¨˜æ†¶é«”å„ªåŒ–
            if self.device == "cuda":
                self.pipe.enable_memory_efficient_attention()
                try:
                    self.pipe.enable_xformers_memory_efficient_attention()
                except:
                    print("âš ï¸ xformers ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨™æº–æ³¨æ„åŠ›æ©Ÿåˆ¶")
            
            print("âœ… Waifu Diffusion è¼‰å…¥æˆåŠŸï¼")
            
        except Exception as e:
            print(f"âŒ Waifu Diffusion è¼‰å…¥å¤±æ•—: {e}")
            print("ğŸ”„ é™ç´šåˆ° Stable Diffusion v1.5...")
            
            # é™ç´šé¸é …
            try:
                self.pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
                    "runwayml/stable-diffusion-v1-5",
                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                    safety_checker=None,
                    requires_safety_checker=False
                ).to(self.device)
                print("âœ… Stable Diffusion v1.5 è¼‰å…¥æˆåŠŸï¼")
            except Exception as e2:
                print(f"âŒ é™ç´šä¹Ÿå¤±æ•—: {e2}")
                raise
    
    def enhance_input_image(self, image):
        """å¢å¼·è¼¸å…¥åœ–åƒçš„å“è³ª"""
        # å¢å¼·å°æ¯”åº¦
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.2)
        
        # å¢å¼·éŠ³åº¦
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(1.1)
        
        return image
    
    def create_base_image(self, original_image):
        """å‰µå»ºé©åˆä¸Šè‰²çš„åŸºç¤åœ–åƒï¼ˆä¸ä½¿ç”¨é‚Šç·£æª¢æ¸¬ï¼‰"""
        # å¢å¼·åŸå§‹åœ–åƒ
        enhanced_image = self.enhance_input_image(original_image)
        
        # è½‰ç‚ºç°éš
        gray_base = ImageOps.grayscale(enhanced_image).convert("RGB")
        
        # å‰µå»ºæ›´å¥½çš„åŸºç¤åœ–åƒ
        # 1. èª¿æ•´äº®åº¦å’Œå°æ¯”åº¦
        enhancer = ImageEnhance.Brightness(gray_base)
        gray_base = enhancer.enhance(1.15)
        
        enhancer = ImageEnhance.Contrast(gray_base)
        gray_base = enhancer.enhance(1.3)
        
        # 2. æ·»åŠ è¼•å¾®çš„æš–è‰²èª¿ï¼Œé©åˆå‹•æ¼«é¢¨æ ¼
        warm_tint = Image.new("RGB", gray_base.size, (255, 248, 240))
        base_image = Image.blend(gray_base, warm_tint, 0.2)
        
        return base_image
    
    def get_universal_prompts(self):
        """é€šç”¨æ¼«ç•«ä¸Šè‰²æç¤ºè© - ä¸é™å®šç‰¹å®šé¢¨æ ¼æˆ–äººç‰©"""
        
        # é€šç”¨çš„æ¼«ç•«ä¸Šè‰²æç¤ºè©
        positive_prompt = """masterpiece, best quality, high resolution, 
        anime style, manga coloring, cel shading, vibrant colors, 
        detailed illustration, clean lineart, professional coloring, 
        colorful anime artwork, detailed shading, bright colors, 
        anime aesthetic, manga art style, high quality coloring"""
        
        # é¿å…ä¸è‰¯æ•ˆæœçš„è² é¢æç¤ºè©
        negative_prompt = """monochrome, grayscale, black and white, 
        sketch, rough lines, unfinished, low quality, blurry, 
        bad anatomy, deformed, ugly, watermark, signature, text, 
        realistic, photorealistic, western cartoon style, 
        oversaturated, muddy colors, dull colors, dark, gloomy"""
        
        return positive_prompt, negative_prompt
    
    def process_image(self, input_image, strength, guidance_scale, num_steps):
        """é€šç”¨æ¼«ç•«åœ–åƒä¸Šè‰²è™•ç†ï¼ˆç„¡é‚Šç·£æª¢æ¸¬ï¼‰"""
        try:
            # èª¿æ•´åœ–åƒå¤§å°ï¼Œä¿æŒæ¯”ä¾‹
            aspect_ratio = input_image.width / input_image.height
            if aspect_ratio > 1:
                new_width = 512
                new_height = int(512 / aspect_ratio)
            else:
                new_height = 512
                new_width = int(512 * aspect_ratio)
            
            # ç¢ºä¿å°ºå¯¸æ˜¯ 8 çš„å€æ•¸
            new_width = (new_width // 8) * 8
            new_height = (new_height // 8) * 8
            
            input_image = input_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # å‰µå»ºåŸºç¤åœ–åƒï¼ˆä¸ä½¿ç”¨é‚Šç·£æª¢æ¸¬ï¼‰
            base_image = self.create_base_image(input_image)
            
            # ç²å–é€šç”¨æç¤ºè©
            prompt, negative_prompt = self.get_universal_prompts()
            
            print(f"ğŸ¨ ä½¿ç”¨é€šç”¨æ¼«ç•«ä¸Šè‰²æç¤ºè©ï¼ˆç„¡é‚Šç·£æª¢æ¸¬ï¼‰")
            
            # ä½¿ç”¨ Waifu Diffusion ç”Ÿæˆ
            result = self.pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                image=base_image,
                strength=strength,
                guidance_scale=guidance_scale,
                num_inference_steps=num_steps,
                eta=0.0
            ).images[0]
            
            # è¿”å›çµæœï¼ˆä¸å†è¿”å›é‚Šç·£åœ–åƒï¼‰
            return result, None
            
        except Exception as e:
            print(f"âŒ è™•ç†å¤±æ•—: {e}")
            return None, None

def create_interface():
    """å‰µå»ºç°¡æ½”çš„ Gradio ä»‹é¢"""
    system = UniversalMangaColoringSystem()
    
    def process_wrapper(image, strength, guidance, steps):
        if image is None:
            return None, "âŒ è«‹ä¸Šå‚³åœ–ç‰‡"
        
        result, _ = system.process_image(image, strength, guidance, steps)
        
        if result is None:
            return None, "âŒ è™•ç†å¤±æ•—"
        
        return result, "âœ… ä¸Šè‰²å®Œæˆï¼"
    
    # ç°¡æ½”çš„ä»‹é¢è¨­è¨ˆ
    with gr.Blocks(title="ğŸ¨ é€šç”¨æ¼«ç•«è‡ªå‹•ä¸Šè‰²", theme=gr.themes.Soft()) as interface:
        gr.Markdown("# ğŸ¨ é€šç”¨æ¼«ç•«è‡ªå‹•ä¸Šè‰²ç³»çµ±")
        gr.Markdown("### ğŸš€ ä¸Šå‚³ä»»ä½•é»‘ç™½æ¼«ç•«åœ–ç‰‡ï¼Œè‡ªå‹•æ™ºèƒ½ä¸Šè‰²")
        
        with gr.Row():
            with gr.Column():
                # è¼¸å…¥å€åŸŸ
                input_image = gr.Image(
                    label="ä¸Šå‚³é»‘ç™½æ¼«ç•«åœ–",
                    type="pil",
                    height=450
                )
                
                # ç°¡åŒ–çš„åƒæ•¸æ§åˆ¶
                with gr.Accordion("ğŸ”§ é€²éšè¨­å®š", open=False):
                    strength = gr.Slider(
                        label="ä¸Šè‰²å¼·åº¦",
                        minimum=0.3,
                        maximum=0.9,
                        value=0.6,
                        step=0.1,
                        info="æ§åˆ¶ä¸Šè‰²çš„å¼·åº¦ï¼Œè¶Šé«˜é¡è‰²è¶Šè±å¯Œ"
                    )
                    
                    guidance_scale = gr.Slider(
                        label="è‰²å½©æŒ‡å°",
                        minimum=8,
                        maximum=20,
                        value=12.0,
                        step=1.0,
                        info="æ§åˆ¶è‰²å½©çš„æº–ç¢ºæ€§"
                    )
                    
                    num_steps = gr.Slider(
                        label="ç”Ÿæˆå“è³ª",
                        minimum=20,
                        maximum=40,
                        value=28,
                        step=2,
                        info="è¶Šé«˜å“è³ªè¶Šå¥½ä½†é€Ÿåº¦è¼ƒæ…¢"
                    )
                
                process_btn = gr.Button("ğŸ¨ è‡ªå‹•ä¸Šè‰²", variant="primary", size="lg")
            
            with gr.Column():
                # è¼¸å‡ºå€åŸŸï¼ˆç°¡åŒ–ï¼‰
                output_image = gr.Image(
                    label="ä¸Šè‰²çµæœ",
                    height=450
                )
                
                status_text = gr.Textbox(
                    label="è™•ç†ç‹€æ…‹",
                    value="ç­‰å¾…ä¸Šå‚³åœ–ç‰‡...",
                    interactive=False
                )
        
        # ä½¿ç”¨èªªæ˜
        gr.Markdown("### ğŸ“– ä½¿ç”¨èªªæ˜")
        gr.Markdown("""
        **âœ¨ åŠŸèƒ½ç‰¹è‰²ï¼š**
        - ğŸ¯ **æ™ºèƒ½è­˜åˆ¥**ï¼šç›´æ¥å¾åŸåœ–è­˜åˆ¥æ¼«ç•«å…§å®¹é€²è¡Œä¸Šè‰²
        - ğŸŒˆ **é€šç”¨ä¸Šè‰²**ï¼šä¸é™å®šç‰¹å®šé¢¨æ ¼ï¼Œé©ç”¨æ–¼å„ç¨®æ¼«ç•«
        - ğŸš€ **ä¸€éµè™•ç†**ï¼šä¸Šå‚³åœ–ç‰‡å³å¯è‡ªå‹•ä¸Šè‰²
        - ğŸ¨ **å°ˆæ¥­æ•ˆæœ**ï¼šä½¿ç”¨ Waifu Diffusion æ¨¡å‹ï¼Œå°ˆç‚ºå‹•æ¼«å„ªåŒ–
        - âš¡ **ç°¡åŒ–æµç¨‹**ï¼šç§»é™¤é‚Šç·£æª¢æ¸¬ï¼Œç›´æ¥é€²è¡Œä¸Šè‰²è™•ç†
        
        **ğŸ“ ä½¿ç”¨æ­¥é©Ÿï¼š**
        1. ä¸Šå‚³é»‘ç™½æ¼«ç•«åœ–ç‰‡ï¼ˆç·šç¨¿ã€é»‘ç™½é é¢ç­‰ï¼‰
        2. é»æ“Šã€Œè‡ªå‹•ä¸Šè‰²ã€æŒ‰éˆ•
        3. ç­‰å¾…è™•ç†å®Œæˆ
        4. å¦‚éœ€èª¿æ•´æ•ˆæœï¼Œå¯å±•é–‹ã€Œé€²éšè¨­å®šã€èª¿æ•´åƒæ•¸
        
        **ğŸ’¡ æ•ˆæœæœ€ä½³çš„åœ–ç‰‡é¡å‹ï¼š**
        - ç·šæ¢æ¸…æ™°çš„é»‘ç™½æ¼«ç•«
        - æœ‰æ˜ç¢ºè¼ªå»“çš„è§’è‰²æˆ–å ´æ™¯
        - å°æ¯”åº¦è¼ƒé«˜çš„åœ–ç‰‡
        
        **âš™ï¸ åƒæ•¸èªªæ˜ï¼š**
        - **ä¸Šè‰²å¼·åº¦**ï¼š0.5-0.7 é©åˆå¤§å¤šæ•¸æƒ…æ³
        - **è‰²å½©æŒ‡å°**ï¼š10-15 ç²å¾—å¹³è¡¡çš„è‰²å½©
        - **ç”Ÿæˆå“è³ª**ï¼š25-30 å¹³è¡¡é€Ÿåº¦èˆ‡æ•ˆæœ
        
        **ğŸ”§ ç³»çµ±å„ªåŒ–ï¼š**
        - ç§»é™¤é‚Šç·£æª¢æ¸¬æ­¥é©Ÿï¼Œæå‡è™•ç†é€Ÿåº¦
        - ç›´æ¥å¾åŸåœ–é€²è¡Œæ™ºèƒ½ä¸Šè‰²
        - æ¸›å°‘è¨ˆç®—é‡ï¼Œé™ä½è¨˜æ†¶é«”ä½¿ç”¨
        """)
        
        # ç¤ºä¾‹åœ–ç‰‡ï¼ˆå¯é¸ï¼‰
        gr.Markdown("### ğŸ–¼ï¸ æ”¯æ´çš„åœ–ç‰‡é¡å‹")
        gr.Markdown("âœ… æ¼«ç•«äººç‰©ã€å ´æ™¯ã€ç‰©å“ã€å»ºç¯‰ã€è‡ªç„¶æ™¯è§€ç­‰å„ç¨®é»‘ç™½æ¼«ç•«å…§å®¹")
        
        # ç¶å®šäº‹ä»¶ï¼ˆç°¡åŒ–è¼¸å‡ºï¼‰
        process_btn.click(
            fn=process_wrapper,
            inputs=[input_image, strength, guidance_scale, num_steps],
            outputs=[output_image, status_text]
        )
    
    return interface

if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹•é€šç”¨æ¼«ç•«è‡ªå‹•ä¸Šè‰²ç³»çµ±ï¼ˆç„¡é‚Šç·£æª¢æ¸¬ç‰ˆï¼‰...")
    interface = create_interface()
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        debug=True
    )